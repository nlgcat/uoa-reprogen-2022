{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3608dd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Reads the GSML CSV file and creates a list where each row is in turn a list of;\n",
    "    - document ID (adjusted for standard prefix of S and numbering from 61 to 90)\n",
    "    - system name (simple form)\n",
    "    - experiment ID (A, B, C)\n",
    "    - error type (one of 6 types)\n",
    "\"\"\"\n",
    "\n",
    "# Convert the test set prefixes and numbering to get sequential IDs\n",
    "test_set_ids = {'T'+str(i).zfill(3)+'.txt':'S'+str(i+60).zfill(3)+'.txt' for i in range(1,31)}\n",
    "\n",
    "def format_doc_id(doc_id):\n",
    "  d = doc_id\n",
    "  if doc_id in test_set_ids:\n",
    "    d = test_set_ids[doc_id]\n",
    "  return d.replace('.txt','')\n",
    "\n",
    "# GSML partition names to experiment IDs\n",
    "def format_exp_id(exp_id):\n",
    "  return {\n",
    "    '00_Existing':  'A',\n",
    "    '01_To_60':     'B',\n",
    "    '02_To_90':     'C',\n",
    "  }[exp_id]\n",
    "\n",
    "# Use a simpler system name than the filenames\n",
    "systems_mapping = {\n",
    "    'wiseman_frototest_conditional_copy_beam5_gens.txt':  'conditional_copy',\n",
    "    'puduppully_aaai_19_rotowire_test.txt':               'document_plan',\n",
    "    'rebuffel_test_gen_not_paper.txt':                    'hierarchical_encoder',\n",
    "  }\n",
    "\n",
    "def format_sys_id(sys_filename):\n",
    "  return systems_mapping[sys_filename]\n",
    "\n",
    "# Read the docs file to get information on each document\n",
    "with open('docs.csv', 'r') as fh:\n",
    "  rows = list(DictReader(fh))\n",
    "  doc_experiments = {format_doc_id(row['DOC_ID']):format_exp_id(row['EXP_ID']) for row in rows}\n",
    "  doc_systems = {format_doc_id(row['DOC_ID']):format_sys_id(row['SYS_ID']) for row in rows}\n",
    "\n",
    "# Read the list of errors and store as per above\n",
    "results = []\n",
    "with open('errors.csv', 'r') as fh:\n",
    "  reader = DictReader(fh)\n",
    "\n",
    "  for row in reader:\n",
    "    doc_id = format_doc_id(row['TEXT_ID'])\n",
    "    sys_id = doc_systems[doc_id]\n",
    "    exp_id = doc_experiments[doc_id]\n",
    "    typ_id = row['TYPE']\n",
    "    results.append([doc_id,sys_id,exp_id,typ_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcdc0800",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A NAME 5.333333333333333\n",
      "B NAME 5.256410256410256\n",
      "C NAME 7.066666666666666\n",
      "\n",
      "A NUMBER 8.857142857142858\n",
      "B NUMBER 7.384615384615385\n",
      "C NUMBER 7.466666666666667\n",
      "\n",
      "A WORD 4.428571428571429\n",
      "B WORD 6.17948717948718\n",
      "C WORD 4.666666666666667\n",
      "\n",
      "A CONTEXT 0.7619047619047619\n",
      "B CONTEXT 0.8974358974358975\n",
      "C CONTEXT 0.26666666666666666\n",
      "\n",
      "A NOT_CHECKABLE 0.19047619047619047\n",
      "B NOT_CHECKABLE 0.8461538461538461\n",
      "C NOT_CHECKABLE 1.2666666666666666\n",
      "\n",
      "A OTHER 0.047619047619047616\n",
      "B OTHER 0.0\n",
      "C OTHER 0.0\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# Dictionary to store measurements for the CV* code\n",
    "measurements = OrderedDict()\n",
    "\n",
    "systems = ['conditional_copy', 'document_plan', 'hierarchical_encoder']\n",
    "experiments = ['A', 'B', 'C']\n",
    "error_types = ['NAME', 'NUMBER', 'WORD', 'CONTEXT', 'NOT_CHECKABLE', 'OTHER']\n",
    "\n",
    "# helper function to initialize document counts at zero\n",
    "def get_experiment_docs(exp_id, sys_id=None):\n",
    "    if sys_id == None:\n",
    "        return {doc_id:0 for doc_id, e_id in doc_experiments.items() if e_id == exp_id }\n",
    "    return {doc_id:0 for doc_id, e_id in doc_experiments.items() if e_id == exp_id and doc_systems[doc_id] == sys_id}\n",
    "    \n",
    "\n",
    "# Dicts to store each of the 4 levels (pre-populate all counts with zero)\n",
    "ensemble_overall = {exp_id:get_experiment_docs(exp_id) for exp_id in experiments}\n",
    "ensemble_type = {typ_id:{exp_id:get_experiment_docs(exp_id) for exp_id in experiments} for typ_id in error_types}\n",
    "system_overall = {\n",
    "    sys_id:{\n",
    "        exp_id:get_experiment_docs(exp_id,sys_id) for exp_id in experiments\n",
    "    } for sys_id in systems\n",
    "}\n",
    "system_type = {\n",
    "    sys_id:{\n",
    "        typ_id:{exp_id:get_experiment_docs(exp_id,sys_id) for exp_id in experiments} for typ_id in error_types\n",
    "    } for sys_id in systems\n",
    "}\n",
    "\n",
    "# Iterate results and record against each of the above\n",
    "for result in results:\n",
    "    doc_id = result[0]\n",
    "    sys_id = result[1]\n",
    "    exp_id = result[2]\n",
    "    typ_id = result[3]\n",
    "    ensemble_overall[exp_id][doc_id] += 1\n",
    "    ensemble_type[typ_id][exp_id][doc_id] += 1\n",
    "    system_overall[sys_id][exp_id][doc_id] += 1\n",
    "    system_type[sys_id][typ_id][exp_id][doc_id] += 1\n",
    "    \n",
    "# Helper function to account for means of empty lists\n",
    "def get_mean(x):\n",
    "    return np.mean(list(x.values()))\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "    Ensemble-Overall measurements\n",
    "\"\"\"\n",
    "\n",
    "values = []\n",
    "for exp_id in experiments:\n",
    "    values.append(get_mean(ensemble_overall[exp_id]))\n",
    "measurements['Ensemble-Overall'] = values\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Ensemble-Type measurements\n",
    "\"\"\"\n",
    "\n",
    "for typ_id in error_types:\n",
    "    key = f'Ensemble-{typ_id}'\n",
    "    values = []\n",
    "    print('')\n",
    "    for exp_id in experiments:\n",
    "        v = get_mean(ensemble_type[typ_id][exp_id])\n",
    "        values.append(v)\n",
    "        print(exp_id, typ_id, v)\n",
    "        \n",
    "    measurements[key] = values\n",
    "\n",
    "\"\"\"\n",
    "    System-Overall measurements\n",
    "\"\"\"\n",
    "\n",
    "for sys_id in systems:\n",
    "    key = f'{sys_id}-Overall'\n",
    "    values = []\n",
    "    for exp_id in experiments:\n",
    "        values.append(get_mean(system_overall[sys_id][exp_id]))\n",
    "    measurements[key] = values\n",
    "\n",
    "\"\"\"\n",
    "    System-Type measurements\n",
    "\"\"\"\n",
    "\n",
    "for sys_id in systems:\n",
    "    for typ_id in error_types:\n",
    "        key = f'{sys_id}-{typ_id}'\n",
    "        values = []\n",
    "        for exp_id in experiments:\n",
    "            values.append(get_mean(system_type[sys_id][typ_id][exp_id]))\n",
    "        measurements[key] = values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "357caec6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 21.0 25.0 17.5 34.0 11.0\n",
      "1 21.0 28.0 18.0 53.0 10.0\n",
      "2 24.0 28.25 21.5 40.0 19.0\n",
      "0 21.0 28.5 18.0 30.0 9.0\n",
      "1 17.0 21.0 14.0 26.0 11.0\n",
      "2 18.0 20.75 14.75 41.0 7.0\n",
      "0 12.0 20.5 10.0 31.0 4.0\n",
      "1 18.0 21.0 14.0 35.0 8.0\n",
      "2 15.0 18.0 12.0 30.0 10.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "  For the box plots\n",
    "\"\"\"\n",
    "\n",
    "import statistics\n",
    "\n",
    "box_data = {sys_id:{exp_id:{} for exp_id in experiments} for sys_id in systems}\n",
    "\n",
    "for result in results:\n",
    "    doc_id = result[0]\n",
    "    sys_id = result[1]\n",
    "    exp_id = result[2]\n",
    "    category = result[3]\n",
    "    \n",
    "    if doc_id not in box_data[sys_id][exp_id]:\n",
    "        box_data[sys_id][exp_id][doc_id] = 0\n",
    "        \n",
    "    box_data[sys_id][exp_id][doc_id] += 1\n",
    "\n",
    "# index median box_top box_bottom whisker_top whisker_bottom\n",
    "for sys_id in systems:\n",
    "    for i, exp_id in enumerate(experiments):\n",
    "        exp_data = box_data[sys_id][exp_id]\n",
    "        values = list(exp_data.values())\n",
    "        x = np.quantile(values, [0.5,0.75,0.25,1,0])\n",
    "        arr = [str(i)] + list([str(y) for y in x])\n",
    "        print(' '.join(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f58e59f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble-Overall & 19.62 & 20.56 & 20.73 & 3.61 \\\\\n",
      "Ensemble-NAME & 5.33 & 5.26 & 7.07 & 21.26 \\\\\n",
      "Ensemble-NUMBER & 8.86 & 7.38 & 7.47 & 12.80 \\\\\n",
      "Ensemble-WORD & 4.43 & 6.18 & 4.67 & 22.80 \\\\\n",
      "Ensemble-CONTEXT & 0.76 & 0.90 & 0.27 & 63.22 \\\\\n",
      "Ensemble-NOT_CHECKABLE & 0.19 & 0.85 & 1.27 & 86.35 \\\\\n",
      "Ensemble-OTHER & 0.05 & 0.00 & 0.00 & 211.73 \\\\\n",
      "conditional_copy-Overall & 21.57 & 25.54 & 26.60 & 13.19 \\\\\n",
      "document_plan-Overall & 21.86 & 17.77 & 18.90 & 13.23 \\\\\n",
      "hierarchical_encoder-Overall & 15.43 & 18.38 & 16.70 & 10.77 \\\\\n",
      "conditional_copy-NAME & 5.57 & 6.00 & 7.80 & 22.39 \\\\\n",
      "conditional_copy-NUMBER & 9.29 & 10.92 & 11.40 & 12.87 \\\\\n",
      "conditional_copy-WORD & 5.86 & 7.15 & 6.00 & 13.72 \\\\\n",
      "conditional_copy-CONTEXT & 0.43 & 0.23 & 0.10 & 79.89 \\\\\n",
      "conditional_copy-NOT_CHECKABLE & 0.43 & 1.23 & 1.30 & 60.02 \\\\\n",
      "conditional_copy-OTHER & 0.00 & 0.00 & 0.00 & -1.00 \\\\\n",
      "document_plan-NAME & 5.71 & 5.08 & 6.40 & 14.12 \\\\\n",
      "document_plan-NUMBER & 11.14 & 6.15 & 7.00 & 40.30 \\\\\n",
      "document_plan-WORD & 4.43 & 5.38 & 3.80 & 21.50 \\\\\n",
      "document_plan-CONTEXT & 0.57 & 0.54 & 0.10 & 79.77 \\\\\n",
      "document_plan-NOT_CHECKABLE & 0.00 & 0.62 & 1.60 & 133.60 \\\\\n",
      "document_plan-OTHER & 0.00 & 0.00 & 0.00 & -1.00 \\\\\n",
      "hierarchical_encoder-NAME & 4.71 & 4.69 & 7.00 & 29.64 \\\\\n",
      "hierarchical_encoder-NUMBER & 6.14 & 5.08 & 4.00 & 25.82 \\\\\n",
      "hierarchical_encoder-WORD & 3.00 & 6.00 & 4.20 & 41.95 \\\\\n",
      "hierarchical_encoder-CONTEXT & 1.29 & 1.92 & 0.60 & 63.71 \\\\\n",
      "hierarchical_encoder-NOT_CHECKABLE & 0.14 & 0.69 & 0.90 & 82.68 \\\\\n",
      "hierarchical_encoder-OTHER & 0.14 & 0.00 & 0.00 & 211.73 \\\\\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Based on https://github.com/asbelz/coeff-var\n",
    "\"\"\"This code computes the coefficient of variation (CV) and some other stats for small samples (indicated by the * added to CV) \n",
    "for a given set of measurements which are assumed to be for the same or similar object, using the same measurand. \n",
    "Stats are adjusted for small sample size. Paper ref: Belz, Popovic & Mille (2022) Quantified Reproducibility Assessment of NLP Results,\n",
    "ACL'22.\n",
    "\n",
    "In this self-contained version, the set of measurements on which CV is computed is assigned to the variable set_of_set_of_measurements\n",
    "(see examples in code below).\n",
    "\n",
    "The reproducibility stats reported in the output are: \n",
    "* the unbiased coefficient of variation\n",
    "* the sample mean\n",
    "* the unbiased sample standard deviation with 95% confidence intervals, estimated on the basis of the standard error of the unbiassed sample variance\n",
    "* the sample size\n",
    "* the percentage of measured valued within two standard deviations\n",
    "* the percentage of measured valued within one standard deviation\n",
    "\n",
    "Example narrative output:\n",
    "\n",
    "The unbiased coefficient of variation is 1.5616560359100269 \\\n",
    "for a mean of 85.58285714285714 , \\\n",
    "unbiased sample standard deviation of 1.2904233075765223 with 95\\% CI (0.4514829817654973, 2.1293636333875474) ,\\\n",
    "and a sample size of 7 . \\\n",
    "100.0 % of measured values fall within two standard deviations. \\\n",
    "71.429 % of measured values fall within one standard deviation. \n",
    "\n",
    "NOTE:\n",
    "* CV assumes all measurements are positive; if they're not, shift measurement scale to start at 0\n",
    "* for fair comparison across studies, measurements on a scale that doesn't start at 0 need to be shifted to a scale that does start at 0 \n",
    "\n",
    "KNOWN ISSUES:\n",
    "\n",
    "none\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "\n",
    "def format_result(key, measurements, cf):\n",
    "    arr = [key] + [str(round(m,2)) for m in measurements] + [str(round(cf,2))]\n",
    "    return ' & '.join(arr)\n",
    "\n",
    "\n",
    "\n",
    "for k, set_of_measurements in measurements.items():\n",
    "  assert len(set_of_measurements) == 3\n",
    "  if len(set_of_measurements) < 2:\n",
    "    print(set_of_measurements, \": set of measurements is smaller than 2\")\n",
    "    continue\n",
    "\n",
    "  sample_mean = np.mean(set_of_measurements)\n",
    "  if sample_mean <= 0:\n",
    "    sample_mean = -1\n",
    "    small_sample_coefficient_of_variation = -1\n",
    "  else:\n",
    "    sample_size = len(set_of_measurements)\n",
    "    degrees_of_freedom = sample_size-1\n",
    "    sum_of_squared_differences = np.sum(np.square(sample_mean-set_of_measurements))\n",
    "\n",
    "    # unbiassed sample variance s^2\n",
    "    unbiassed_sample_variance = sum_of_squared_differences/degrees_of_freedom\n",
    "    # corrected sample standard deviation s\n",
    "    corrected_sample_standard_deviation = np.sqrt(unbiassed_sample_variance)\n",
    "    # Gamma(N/2)\n",
    "    gamma_N_over_2 = math.gamma(sample_size/2)\n",
    "    # Gamma((N-1)/2)\n",
    "    gamma_df_over_2 = math.gamma(degrees_of_freedom/2)\n",
    "    # c_4(N)\n",
    "    c_4_N = math.sqrt(2/degrees_of_freedom)*gamma_N_over_2/gamma_df_over_2\n",
    "    # unbiassed sample std dev s/c_4\n",
    "    unbiassed_sample_std_dev_s_c_4 = corrected_sample_standard_deviation/c_4_N\n",
    "    # standard error of the unbiassed sample variance (assumes normally distributed population)\n",
    "    standard_error_of_unbiassed_sample_variance = unbiassed_sample_variance*np.sqrt(2/degrees_of_freedom)\n",
    "    # estimated std err of std dev based on std err of unbiassed sample variance\n",
    "    est_SE_of_SD_based_on_SE_of_unbiassed_sample_variance = standard_error_of_unbiassed_sample_variance/(2*unbiassed_sample_std_dev_s_c_4)\n",
    "\n",
    "    # COEFFICIENT OF VARIATION CV\n",
    "    coefficient_of_variation = (unbiassed_sample_std_dev_s_c_4/sample_mean)*100\n",
    "    # SMALL SAMPLE CORRECTED COEFFICIENT OF VARIATION CV*\n",
    "    small_sample_coefficient_of_variation = (1+(1/(4*sample_size)))*coefficient_of_variation\n",
    "\n",
    "    # compute percentage of measured values within 1 and 2 standard deviations from the mean\n",
    "    # initialise counts\n",
    "    count_within_1_sd = 0\n",
    "    count_within_2_sd = 0\n",
    "    # for each measured value\n",
    "    for m in set_of_measurements:\n",
    "      # if it's within two std devs, increment count_within_2_sd\n",
    "      if np.abs(m-sample_mean) < 2*unbiassed_sample_std_dev_s_c_4:\n",
    "        count_within_2_sd += 1\n",
    "        #if it's also within one std devs, increment count_within_1_sd\n",
    "        if np.abs(m-sample_mean) < unbiassed_sample_std_dev_s_c_4:\n",
    "          count_within_1_sd += 1\n",
    "        \n",
    "  # Print results for the latex tables (all values are calculated then final values rounded)\n",
    "  arr = [k] + [('%.2f' % m) for m in set_of_measurements] + ['%.2f' % small_sample_coefficient_of_variation]\n",
    "  print(' & '.join(arr) + ' \\\\\\\\')\n",
    "\n",
    "  # report results as described in code description above\n",
    "#   print(f\"The unbiased coefficient of variation ({k}) is\",small_sample_coefficient_of_variation)\n",
    "#   print(\"for a mean of\",sample_mean,\", \")\n",
    "#   print(\"unbiased sample standard deviation of\",unbiassed_sample_std_dev_s_c_4,\", with 95\\% CI\",t.interval(0.95, degrees_of_freedom, loc=unbiassed_sample_std_dev_s_c_4, scale=est_SE_of_SD_based_on_SE_of_unbiassed_sample_variance),\",\")\n",
    "#   print(\"and a sample size of\",sample_size,\".\")\n",
    "#   print(count_within_2_sd/sample_size*100,\"% of measured values fall within two standard deviations.\")\n",
    "#   print(round(count_within_1_sd/sample_size*100, 3),\"% of measured values fall within one standard deviation.\", )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de097225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106199f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
